{
	"jobConfig": {
		"name": "category_tree_cleaning_job_with_graphframes",
		"description": "",
		"role": "arn:aws:iam::727618352148:role/AWSGlueRoleForEcommerceProject",
		"command": "glueetl",
		"version": "5.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 10,
		"maxCapacity": 10,
		"jobRunQueuingEnabled": false,
		"maxRetries": 0,
		"timeout": 480,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "category_tree_cleaning_job_with_graphframes.py",
		"scriptLocation": "s3://ecommerce-user-behavior-2025/scripts/",
		"language": "python-3",
		"spark": true,
		"sparkConfiguration": "standard",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2025-07-24T00:39:11.372Z",
		"developerMode": true,
		"connectionsList": [],
		"temporaryDirectory": "s3://ecommerce-user-behavior-2025/temp/",
		"glueHiveMetastore": true,
		"etlAutoTuning": true,
		"metrics": true,
		"observabilityMetrics": true,
		"dependentPath": "s3://ecommerce-user-behavior-2025/jars/graphframes-spark3_2.12-0.9.2.jar",
		"bookmark": "job-bookmark-disable",
		"sparkPath": "s3://aws-glue-assets-727618352148-ca-central-1/sparkHistoryLogs/",
		"flexExecution": false,
		"minFlexWorkers": null,
		"maintenanceWindow": null
	},
	"hasBeenSaved": false,
	"usageProfileName": null,
	"script": "import sys\r\nfrom pyspark.sql import functions as F\r\nfrom pyspark.sql.types import IntegerType\r\nfrom awsglue.utils import getResolvedOptions\r\nfrom awsglue.context import GlueContext\r\nfrom awsglue.job import Job\r\nfrom pyspark.context import SparkContext\r\n\r\n# AWS Glue boilerplate\r\nargs = getResolvedOptions(sys.argv, ['JOB_NAME'])\r\nsc = SparkContext()\r\nglueContext = GlueContext(sc)\r\nspark = glueContext.spark_session\r\njob = Job(glueContext)\r\njob.init(args['JOB_NAME'], args)\r\n\r\n# Step 1: Load category_tree.csv with schema enforcement\r\nschema = \"categoryid INT, parentid INT\"\r\ndf = spark.read.option(\"header\", True) \\\r\n               .option(\"nullValue\", \"\\\\N\") \\\r\n               .schema(schema) \\\r\n               .csv(\"s3://ecommerce-user-behavior-2025/raw-data/retailrocket/category_tree.csv\")\r\n\r\nprint(f\"Initial row count: {df.count()}\")\r\n\r\n# Step 2: Drop null/invalid/duplicate/self-linked rows\r\ndf = df.dropna(subset=[\"categoryid\"])\r\ndf = df.filter(F.col(\"categoryid\") > 0)\r\ndf = df.dropDuplicates([\"categoryid\", \"parentid\"])\r\ndf = df.filter(~(F.col(\"categoryid\") == F.col(\"parentid\")))  # Remove self-parenting\r\n\r\n# Step 3: Identify root nodes and orphans\r\ndf = df.withColumn(\"is_root\", F.col(\"parentid\").isNull())\r\n\r\n# Create set of valid category IDs\r\nvalid_ids = df.select(\"categoryid\").distinct()\r\n\r\n# Orphan detection: parentid exists but not in categoryid list\r\norphans = df.filter(F.col(\"parentid\").isNotNull()) \\\r\n            .join(valid_ids, df.parentid == valid_ids.categoryid, how=\"left_anti\")\r\n\r\nprint(f\"Orphan parent count: {orphans.count()}\")\r\n\r\n# Optional: Resolve orphans by making them root\r\norphan_ids = [row[\"parentid\"] for row in orphans.select(\"parentid\").distinct().collect()]\r\ndf = df.withColumn(\"parentid\", F.when(F.col(\"parentid\").isin(orphan_ids), None).otherwise(F.col(\"parentid\")))\r\n\r\n# Re-evaluate root categories\r\ndf = df.withColumn(\"is_root\", F.col(\"parentid\").isNull())\r\n\r\n# Step 4: Add level metadata using iterative method (max 5 levels)\r\ndf = df.withColumn(\"level\", F.lit(None).cast(\"int\"))\r\ndf = df.withColumn(\"path\", F.col(\"categoryid\").cast(\"string\"))\r\n\r\nfor i in range(1, 6):  # max depth 5\r\n    if i == 1:\r\n        df = df.withColumn(\"level\", F.when(F.col(\"is_root\"), 1).otherwise(None))\r\n    else:\r\n        parent_levels = df.select(\r\n            F.col(\"categoryid\").alias(\"pid\"),\r\n            F.col(\"level\").alias(\"plevel\"),\r\n            F.col(\"path\").alias(\"ppath\")\r\n        )\r\n        df = df.join(parent_levels, df.parentid == parent_levels.pid, how=\"left\") \\\r\n               .withColumn(\"level\", F.when(F.col(\"plevel\").isNotNull(), F.col(\"plevel\") + 1).otherwise(F.col(\"level\"))) \\\r\n               .withColumn(\"path\", F.when(F.col(\"ppath\").isNotNull(), F.concat(F.col(\"ppath\"), F.lit(\" > \"), F.col(\"categoryid\").cast(\"string\"))).otherwise(F.col(\"path\"))) \\\r\n               .drop(\"pid\", \"plevel\", \"ppath\")\r\n\r\n# Step 5: Final validation\r\ndf = df.withColumn(\"level\", F.when(F.col(\"level\").isNull(), 1).otherwise(F.col(\"level\")))\r\ndf = df.withColumn(\"path\", F.when(F.col(\"path\").isNull(), F.col(\"categoryid\").cast(\"string\")).otherwise(F.col(\"path\")))\r\n\r\nprint(\"Hierarchy levels:\")\r\ndf.groupBy(\"level\").count().orderBy(\"level\").show()\r\n\r\n# Step 6: Save cleaned + enriched category tree\r\ndf.repartition(1).write.mode(\"overwrite\").parquet(\"s3://ecommerce-user-behavior-2025/cleaned-data/category_tree/\")\r\n\r\nprint(\"âœ… category_tree.csv cleaned and enriched successfully.\")\r\njob.commit()\r\n"
}